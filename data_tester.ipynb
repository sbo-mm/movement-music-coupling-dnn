{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbadbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import joblib\n",
    "import glob\n",
    "\n",
    "from data_utils.mg_sg_generator import get_dataset_ids, get_dataset_for\n",
    "from data_utils.mg_sg_generator import MotiongramSpectrogramGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81defc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Wrote 1056 files to /home/sbol13/sbol_data/datasets/mg_sg_pair_129x128_train_1056\n",
      "[validation] Wrote 227 files to /home/sbol13/sbol_data/datasets/mg_sg_pair_129x128_validation_227\n",
      "[test] Wrote 227 files to /home/sbol13/sbol_data/datasets/mg_sg_pair_129x128_test_227\n"
     ]
    }
   ],
   "source": [
    "fout = get_dataset_for(nfft=256)\n",
    "for k, v in fout.items():\n",
    "    print(f'[{k}] Wrote {v[0]} files to {v[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c42e01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfr_example(example):\n",
    "    data = {\n",
    "        'motiongram'  : tf.io.FixedLenFeature([], tf.string),\n",
    "        'spectrogram' : tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    content = tf.io.parse_single_example(example, data)\n",
    "    mg, sg = content['motiongram'], content['spectrogram']\n",
    "    mg_feature = tf.reshape(tf.io.parse_tensor(mg, out_type=tf.float32), shape=[129*128])\n",
    "    sg_feature = tf.reshape(tf.io.parse_tensor(sg, out_type=tf.float32), shape=[129*128])\n",
    "    return mg_feature, sg_feature\n",
    "\n",
    "def get_dataset_small(filename):\n",
    "    # create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "    # pass every single feature through our mapping function\n",
    "    dataset = dataset.map(\n",
    "      parse_tfr_example\n",
    "    )\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def input_fn(filename, batch_size):\n",
    "    ds = get_dataset_small(filename)\n",
    "    ds = ds.shuffle(10000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.repeat()\n",
    "    #ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c33be2",
   "metadata": {},
   "source": [
    "### Setup a simple test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b749a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(129*128, ))\n",
    "x = Dense(100)(inp)\n",
    "out = Dense(129*128)(x)\n",
    "\n",
    "model = Model(inputs=[inp], outputs=[out])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b6d0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 100\n",
    "\n",
    "ds_train      = input_fn(fout[\"train\"][-1], batch_size=batch_size)\n",
    "ds_validation = input_fn(fout[\"validation\"][-1], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4184cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 10 steps, validate for 2 steps\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.0184 - accuracy: 0.0030 - val_loss: 0.0232 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0182 - accuracy: 0.0042 - val_loss: 0.0238 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0177 - accuracy: 0.0052 - val_loss: 0.0244 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.0176 - accuracy: 0.0021 - val_loss: 0.0238 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0178 - accuracy: 0.0042 - val_loss: 0.0244 - val_accuracy: 0.0100\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.0180 - accuracy: 0.0063 - val_loss: 0.0242 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0171 - accuracy: 0.0084 - val_loss: 0.0237 - val_accuracy: 0.0050\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0166 - accuracy: 0.0052 - val_loss: 0.0233 - val_accuracy: 0.0050\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.0159 - accuracy: 0.0052 - val_loss: 0.0244 - val_accuracy: 0.0100\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0157 - accuracy: 0.0021 - val_loss: 0.0242 - val_accuracy: 0.0050\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0156 - accuracy: 0.0063 - val_loss: 0.0249 - val_accuracy: 0.0050\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.0160 - accuracy: 0.0110 - val_loss: 0.0248 - val_accuracy: 0.0250\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0156 - accuracy: 0.0146 - val_loss: 0.0239 - val_accuracy: 0.0150\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0149 - accuracy: 0.0084 - val_loss: 0.0241 - val_accuracy: 0.0050\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0151 - accuracy: 0.0115 - val_loss: 0.0272 - val_accuracy: 0.0150\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.0152 - accuracy: 0.0115 - val_loss: 0.0253 - val_accuracy: 0.0100\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0141 - accuracy: 0.0105 - val_loss: 0.0252 - val_accuracy: 0.0200\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0138 - accuracy: 0.0188 - val_loss: 0.0241 - val_accuracy: 0.0050\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.0136 - accuracy: 0.0115 - val_loss: 0.0275 - val_accuracy: 0.0200\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0145 - accuracy: 0.0136 - val_loss: 0.0263 - val_accuracy: 0.0250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f71ec6b3d90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=1056//100,\n",
    "    validation_data=ds_validation,\n",
    "    validation_steps=227//100,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "g = gen[0]\n",
    "mg, sg = g\n",
    "mg_0 = np.reshape(mg[0, :], newshape=(129, 128))\n",
    "sg_0 = np.reshape(sg[0, :], newshape=(129, 128))\n",
    "mg_1 = np.reshape(mg[-1, :], newshape=(129, 128))\n",
    "sg_1 = np.reshape(sg[-1, :], newshape=(129, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axs[0, 0].set_xticks([])\n",
    "axs[0, 0].set_yticks([])\n",
    "axs[0, 0].set_xlabel(\"(a) Input Motiongram\")\n",
    "axs[0, 0].imshow(mg_0, aspect=\"auto\", cmap=\"Spectral_r\", interpolation=\"bicubic\")\n",
    "\n",
    "axs[0, 1].set_xticks([])\n",
    "axs[0, 1].set_yticks([])\n",
    "axs[0, 1].set_xlabel(\"(a) Input Motiongram\")\n",
    "axs[0, 1].imshow(mg_1, aspect=\"auto\", cmap=\"Spectral_r\", interpolation=\"bicubic\")\n",
    "\n",
    "axs[1, 0].set_xticks([])\n",
    "axs[1, 0].set_yticks([])\n",
    "axs[1, 0].set_xlabel(\"(a) Input Motiongram\")\n",
    "axs[1, 0].imshow(np.flipud(sg_0), aspect=\"auto\", cmap=\"Spectral_r\", interpolation=\"bicubic\")\n",
    "\n",
    "axs[1, 1].set_xticks([])\n",
    "axs[1, 1].set_yticks([])\n",
    "axs[1, 1].set_xlabel(\"(a) Input Motiongram\")\n",
    "axs[1, 1].imshow(np.flipud(sg_1), aspect=\"auto\", cmap=\"Spectral_r\", interpolation=\"bicubic\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf74071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
