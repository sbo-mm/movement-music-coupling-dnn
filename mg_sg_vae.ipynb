{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e486b3b3",
   "metadata": {},
   "source": [
    "#### Meaningful description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a6220b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tensorflow v. 2.4.1\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "Number of devices: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Import and setup the tensorflow session\n",
    "import tensorflow as tf\n",
    "\n",
    "# Sanity check to ensure we are on correct tensorflow version\n",
    "print(\"Using Tensorflow v. %s\"%tf.__version__); assert tf.__version__ == \"2.4.1\";\n",
    "\n",
    "# Setup a strategy to distribute resources and training\n",
    "# across all available GPUs on the system.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Check number of GPUs used by the distribution scope.\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3d9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tf contrib modules\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# Import Keras modules\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Import from custom modules\n",
    "from data_utils.mg_sg_generator import strip_file\n",
    "from data_utils.mg_sg_generator import get_dataset_for, splice_spectrogram_patches\n",
    "from data_utils.mg_sg_generator import prepare_dataset_for_training, prepare_dataset_for_evaluation\n",
    "\n",
    "from data_utils.sg_preprocessor import spectrogram2audio\n",
    "from data_utils.sg_preprocessor import inverse_normalize_db_0_1, FNCOLS \n",
    "\n",
    "# Import custom tensorflow utilities\n",
    "from tf_extensions.tf_custom.models import GaussianBetaVAE\n",
    "from tf_extensions.tf_custom.models import make_cnn_vae_encoder, make_dense_vae_decoder\n",
    "\n",
    "# Common utilities\n",
    "import numpy as np\n",
    "\n",
    "# Display utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Pathing (using absolute paths for now)\n",
    "BASE_DATA_PATH = \"/home/sbol13/sbol_data\"\n",
    "MW_SAVE_PATH   = BASE_DATA_PATH + \"/model_weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9242e9",
   "metadata": {},
   "source": [
    "#### Utility functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f60615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mvn(x_mu, x_logvar):\n",
    "    x_sig = np.exp(x_logvar)\n",
    "    batch = x_sig.shape[0]\n",
    "    mvn = tfp.distributions.MultivariateNormalDiag(\n",
    "        loc=x_mu, scale_diag=x_sig\n",
    "    )\n",
    "    return mvn.sample(shape=[batch]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7342f8",
   "metadata": {},
   "source": [
    "### Prepare and Setup Data\n",
    "Construct and/or load the datasets we need for the various experiments:\n",
    "- Linear Spectrogram <b>(r128xc128)</b>, latent dim: 256\n",
    "- Linear Spectrogram <b>(r512xc128)</b>, latent dim: 256\n",
    "- Linear Spectrogram <b>(r512xc128)</b>, latent dim: 256x4 (2048)\n",
    "\n",
    "Where rNUM indicated the FFT bins (i.e. the FFT-size) used to compute the spectrograms we are attempting to predict. cNUM is simply the STFT columns, which are a direct result of the <i>hop_size</i> we use.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db8edb6",
   "metadata": {},
   "source": [
    "#### Globals for all experiments: \n",
    "Some variables are held constant throughout the different models under experimentation.\n",
    "We use the block below to define these, such that we can re-use them throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18215108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience lambda(s) to retrieve information\n",
    "# about a relevant .tfrecords file (nexamples, filepath)\n",
    "TFR_TRAIN      = lambda tfr_dict: tfr_dict[\"train\"]\n",
    "TFR_VALIDATION = lambda tfr_dict: tfr_dict[\"validation\"]\n",
    "TFR_TEST       = lambda tfr_dict: tfr_dict[\"test\"]\n",
    "TFR_PATH       = lambda tfr_tuple: tfr_tuple[-1]\n",
    "\n",
    "# Define a small lambda to compute the columns\n",
    "# to use for each nn input. TODO: FINISH\n",
    "NCOLS = lambda hl: FNCOLS(hl)\n",
    "\n",
    "# Define a small lambda to compute the rows\n",
    "# to use for each nn input.\n",
    "NROWS = lambda nfft: nfft//2 + 1\n",
    "\n",
    "# Define the train-size percentage.\n",
    "# This value indicates how much of the dataset is reserved for training. \n",
    "# The remaining is split evenly into validation/testing.\n",
    "# (i.e. a split could be 70-15-15)\n",
    "TRAIN_SIZE = 0.7\n",
    "\n",
    "# Define a flag to indicate whether we should\n",
    "# recompute all the datasets.\n",
    "DS_OVERWRITE = True\n",
    "\n",
    "# Define the beta-value to use for tuning the VAE(s).\n",
    "VAE_BETA = 1.\n",
    "\n",
    "# Define the learning rate to apply across\n",
    "# all training conditions.\n",
    "BASE_LR = 2e-04 \n",
    "\n",
    "# Define the optimizer to use for training across\n",
    "# all conditions.\n",
    "OPTIMIZER = optimizers.Adam(lr=BASE_LR)\n",
    "\n",
    "# Define batch size to use for training.\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Define a lambda to retrieve the step size(s).\n",
    "STEPS_PER_EPOCH = lambda tfr_tuple: tfr_tuple[0] // BATCH_SIZE\n",
    "\n",
    "# Lambda to retrieve savepath to model weights\n",
    "MW_SAVEPATH_FN = lambda meta_dict:\\\n",
    "    f'{MW_SAVE_PATH}/{strip_file(TFR_PATH(TFR_TRAIN(meta_dict)))}.h5'\n",
    "\n",
    "# Define a function to return a callback for model saving. \n",
    "# (setup saving weights incrementally)\n",
    "def CHECKPOINT_CALLBACK(meta_dict, save_step=20):\n",
    "    # Compute save frequency\n",
    "    SF = STEPS_PER_EPOCH(TFR_TRAIN(meta_dict)) * save_step \n",
    "\n",
    "    # Make callback instance\n",
    "    CHECKPOINT = ModelCheckpoint(\n",
    "        MW_SAVEPATH_FN(meta_dict), \n",
    "        monitor           = 'ELBO', \n",
    "        save_freq         = SF,\n",
    "        save_best_only    = True,\n",
    "        save_weights_only = True,\n",
    "        mode              ='auto',\n",
    "        verbose           = 1\n",
    "    )\n",
    "    return CHECKPOINT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81afca",
   "metadata": {},
   "source": [
    "#### Approach 1 (AP1): Linspect r128xc128, latent dim 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbfe3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FFT-size.\n",
    "ap1_nfft = 256\n",
    "\n",
    "# Define the hop_length (overlap)\n",
    "# in samples.\n",
    "ap1_overlap = ap1_nfft // 2\n",
    "\n",
    "# Define the latent dimension size.\n",
    "ap1_latent_dim = 256\n",
    "\n",
    "# Fetch a dataset that fullfils the \n",
    "# requirements for this condition.\n",
    "ap1_fout = get_dataset_for(\n",
    "    nfft               = ap1_nfft,\n",
    "    overlap            = ap1_overlap,\n",
    "    train_size         = TRAIN_SIZE, \n",
    "    overwrite_existing = DS_OVERWRITE\n",
    ")\n",
    "\n",
    "# Prepare the input/output shape(s).\n",
    "ap1_inout_shape_train = (NROWS(ap1_nfft), TFR_TRAIN(ap1_fout)[2])\n",
    "\n",
    "# Fetch a deep learning model (VAE) \n",
    "# for this condition.\n",
    "#with strategy.scope():\n",
    "ap1_vae = GaussianBetaVAE(\n",
    "    N                   = TFR_TRAIN(ap1_fout)[0],\n",
    "    M                   = BATCH_SIZE,\n",
    "    beta                = VAE_BETA,\n",
    "    input_dim           = ap1_inout_shape_train,\n",
    "    latent_dim          = ap1_latent_dim,\n",
    "    create_encoder_func = make_cnn_vae_encoder,\n",
    "    create_decoder_func = make_dense_vae_decoder\n",
    ")\n",
    "\n",
    "# Compile the model and make ready for training.\n",
    "ap1_vae.custom_compile(optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c9a651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  Type mismatch between parsed tensor (double) and dtype (float)\n\t [[{{node ParseTensor_1}}]]\n\t [[IteratorGetNext]]\n  (1) Invalid argument:  Type mismatch between parsed tensor (double) and dtype (float)\n\t [[{{node ParseTensor_1}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_20]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_83350]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12437/3199862045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTFR_VALIDATION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map1_fout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mepochs\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcallbacks\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCHECKPOINT_CALLBACK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map1_fout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/SBO-ML/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SBO-ML/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SBO-ML/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SBO-ML/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SBO-ML/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/SBO-ML/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/SBO-ML/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  Type mismatch between parsed tensor (double) and dtype (float)\n\t [[{{node ParseTensor_1}}]]\n\t [[IteratorGetNext]]\n  (1) Invalid argument:  Type mismatch between parsed tensor (double) and dtype (float)\n\t [[{{node ParseTensor_1}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_20]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_83350]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset(s) for training.\n",
    "ap1_ds_train = prepare_dataset_for_training(\n",
    "    filename     = TFR_PATH(TFR_TRAIN(ap1_fout)),\n",
    "    batch_size   = BATCH_SIZE,\n",
    "    cast_to_type = tf.float64\n",
    ")\n",
    "\n",
    "ap1_ds_validation = prepare_dataset_for_training(\n",
    "    filename     = TFR_PATH(TFR_VALIDATION(ap1_fout)),\n",
    "    batch_size   = BATCH_SIZE,\n",
    "    cast_to_type = tf.float64\n",
    ")\n",
    "\n",
    "# Train the vae model.\n",
    "ap1_history = ap1_vae.fit(\n",
    "    ap1_ds_train,\n",
    "    steps_per_epoch  = STEPS_PER_EPOCH(TFR_TRAIN(ap1_fout)),\n",
    "    validation_data  = ap1_ds_validation,\n",
    "    validation_steps = STEPS_PER_EPOCH(TFR_VALIDATION(ap1_fout)),\n",
    "    epochs           = 100,\n",
    "    callbacks        = [CHECKPOINT_CALLBACK(ap1_fout)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267624b",
   "metadata": {},
   "source": [
    "#### Evaluate AP1 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = TFR_TRAIN(ap1_fout)\n",
    "batch_div = train_meta[0] // train_meta[1]\n",
    "ap1_ds_test = prepare_dataset_for_evaluation(\n",
    "    filename     = TFR_PATH(TFR_TRAIN(ap1_fout)),\n",
    "    batch_size   = batch_div,\n",
    "    cast_to_type = tf.float64\n",
    ")\n",
    "ds_iter = iter(ap1_ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_, _ = ds_iter.get_next()\n",
    "mu_x, logvar_x, _, _ = ap1_vae.predict(mg_)\n",
    "print(mu_x.shape, logvar_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "specgram = sample_mvn(mu_x, logvar_x)\n",
    "print(specgram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "specgram_patches_np = np.reshape(specgram, newshape=(batch_div, NROWS(ap1_nfft), -1))\n",
    "specgram_patches = [specgram_patches_np[p, ...] for p in range(batch_div)]\n",
    "specgram_spliced = splice_spectrogram_patches(specgram_patches, NCOLS(ap1_overlap))\n",
    "print(specgram_spliced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529de5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(10, 10))\n",
    "axs.set_xticks([]); axs.set_yticks([]);\n",
    "axs.imshow(\n",
    "    np.flipud(specgram_spliced), \n",
    "    aspect=\"auto\", \n",
    "    cmap=\"Spectral_r\", \n",
    "    interpolation=\"bicubic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = spectrogram2audio(\n",
    "    specgram_spliced, \n",
    "    ap1_overlap, \n",
    "    True\n",
    ")\n",
    "print(y.shape)\n",
    "ipd.display(ipd.Audio(y, rate=22050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab904a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MW_SAVEPATH_FN(ap1_fout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21682aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
